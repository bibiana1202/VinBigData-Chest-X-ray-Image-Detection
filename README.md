# VinBigData-Chest-X-ray-Image-Detection

- VinBigData Chest X-ray Image Detection : <a href="https://www.notion.so/wew1202/VinBigData-Chest-X-ray-Detection-5c03f0811f5a47adb314f918795a2056">![Notion](https://img.shields.io/badge/Notion-%23000000.svg?style=for-the-badge&logo=notion&logoColor=white)

- Kaggle - VinBigData chest X-ray abnormalities detection contest : <a href="https://www.kaggle.com/competitions/vinbigdata-chest-xray-abnormalities-detection/overview">![kaggle](https://img.shields.io/badge/-kaggle-blue)  
    
---
## ğŸ« Introduction
* ### Why Chest X-ray?

  - Chest X-rayëŠ” ê¸°ë³¸ì¤‘ì— ê¸°ë³¸ì¸ ê²€ì‚¬.
  - ìƒëª…ê³¼ ì§ê²°ë˜ëŠ” ë¶€ìœ„ì´ê¸° ë•Œë¬¸ì— ì •í™•í•œ ì§„ë‹¨ì´ í•„ìš”í•˜ë‹¤.
  - ë‹¤ë¥¸ ë¶€ìœ„ì˜ X-rayì™€ëŠ” ë‹¤ë¥´ê²Œ ë†“ì¹  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¶€ìœ„ë¼ ë§ê³  ë§ì€ X-ray dataì¤‘ chest X-rayë¥¼ ì„ íƒí•˜ì˜€ë‹¤.
* ### Why Chest X-ray needs AI?

  - ì˜ˆë¥¼ ë“¤ì–´ ì¢…ì–‘ íŒë…ì˜ ê²½ìš° ì¢…ì–‘ì´ í¬ë‹¤ë©´ ëˆ„êµ¬ë‚˜ íŒë…ì´ ê°€ëŠ¥í•˜ë‹¤. í•˜ì§€ë§Œ ë§Œì•½ ê²°ì ˆì˜ sizeê°€ ì‘ë‹¤ë©´ ë†“ì¹  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ì´ë ‡ê²Œ ë³‘ë³€ì„ ë†“ì¹˜ì§€ ì•Šê¸°ìœ„í•´ AIê°€ ì˜ì‚¬ì˜ ë„ì›€ì´ ë˜ì–´ ì§„ë‹¨ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.
ë˜í•œ ì¼ë°˜ X-ray ì „ë¬¸ì˜ì‚¬(ë°©ì‚¬ì„ ê³¼)ê°€ ì•„ë‹ˆë”ë¼ë„ íŒë…ì— ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆê¸°ë•Œë¬¸ì— AIë¥¼ ì´ìš©í•œë‹¤ë©´ ì¢€ ë” ì •í™•í•˜ê²Œ íŒë…ì´ ê°€ëŠ¥í•  ê²ƒì´ë‹¤.

* ### purpose
  - íì™€ ê´€ë ¨ëœ 14ê°€ì§€ì˜ ì§ˆë³‘ì„ detectingí•˜ì—¬ data augmentationì— ë”°ë¥¸ ì—¬ëŸ¬ modelì˜ performance ë¹„êµ
---
## ğŸ« Materials & Methods
* ### Materials
  
  - Vietnam hospitals dataset (the Hospital 108 and the Hanoi Medical University Hospital)
  - train images: 15,000 (normal: 10,606, patient: 4,394)
  - test images: 3,000
  - bbox info: image_id, class_id, x_min, y_min, x_max, y_max
  - image resize: 512 x 512 , 1024 x 1024
  - ë³‘ëª… ì‚¬ì „ì¡°ì‚¬ : <a href="https://www.notion.so/wew1202/8204385788fd45c1adeb7c0c7dc5e4db">![Notion](https://img.shields.io/badge/Notion-%23000000.svg?style=for-the-badge&logo=notion&logoColor=white)
  
* ### Methods
  - Tools: OpenCV, PyTorch, numpy, pandas, sklearn, seaborn, matplotlib
  - Augmentations: Rotation(random), Flip(horizontal), Zoomin(10%), Cutmix, CLAHE, Equlization
  - Models: Faster RCNN, YOLOv5, RetinaNet, Yolof, Yolox, CenterNet
  - Workflow : 
  
  
  
---
## ğŸ« Results
* ### EDA
![https://user-images.githubusercontent.com/61971952/193209874-ebc78a59-5b58-4816-8412-c841a3b6099f.png](https://user-images.githubusercontent.com/61971952/193209874-ebc78a59-5b58-4816-8412-c841a3b6099f.png)
    
    - ì •ìƒì¸ì˜ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ì ì€ ì–‘ì˜ í™˜ì ë°ì´í„°ë§Œ ë‚¨ìŒ
    - ë¼ë²¨ ê°„ì˜ ê·¹ë‹¨ì ì¸ ì–‘ ì°¨ì´ -> ë°ì´í„° ë¶ˆê· í˜•
    - ë‹¨ì¼ ì´ë¯¸ì§€ì•ˆì— ë‹¤ì¤‘ ë¼ë²¨
    
* ### Augmentationì— ë”°ë¥¸ dataset ì¢…ë¥˜

    - category A: no augmentation (15000ì¥)
    - category B: rotation, flip, zoomin (15000ì¥ + 6250ì¥)
    - categroy C: rotation, flip, zoomin(10%), CLAHE, equalization (15000ì¥ + 6250ì¥)


* ### Modelì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ(kaggle score)

M/D	| 512 A | 512 B | 512 C | 1024A | 1024B | 1024C |
--------------|-------|-------|-------|-------|-------|-------|
Faster R-CNN | 0.013/0.016 | 0.135/0.124 | --- | 0.131/0.110 | 0.137/0.127 | 0.123/0.154 |
Yolov5 | 0.179/0.149 | 0.114/0.095  | 0.119/0.090 | ì§„í–‰ì¤‘ | ì§„í–‰ì¤‘ | ì§„í–‰ì¤‘ |
RetinaNet | 0.041/0.043 | --- | --- | 0.135/0.114 | 0.126/0.132 | 0.142/0.121 |
Yolof | 0.039/0.041 | --- | --- | 0.142/0.106 | 0.135/0.122 | 0.126/0.108 |
Yolox | 0.145/0.112 | 0.108/0.077 | --- | 0.141/0.118 | 0.127/0.137 | 0.179/0.156 |
CenterNet | 0.038/0.039 | --- | --- | 0.069/0.065 | --- | 0.083/0.077 |

* ### ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ(kaggle score)
  - 2-pred score
    
n | WBF | Faster R-CNN | Yolov5 | RetinaNet | Yolof | Yolox | SCORE |
--------------|-------|-------|-------|-------|-------|-------|-------|
#1 | Faster,Retina | 1024A(0.131/0.110) | - | 1024A(0.135/0.114) | - | - | 0.179/0.151 |
#2 | Faster,yolov5 | 1024A(0.131/0.110) | 512A KFLOD(0.179/0.149) | - | - | - | 0.210/0.196 |
#3 | Retina,yolov5 | - | 512A KFLOD(0.179/0.149) | 1024A(0.135/0.114) | - | - | 0.212/0.204 |
#4 | Faster,yolov5,Retina | 1024A(0.131/0.110) | 512A KFLOD (0.179/0.149) | 1024A (0.135/0.114) | - | - | 0.216/0.209 |
#5 | yolov5,yolovf | - | 512A KFLOD (0.179/0.149) | - | 1024A (0.142/0.106) | - | 0.218/0.205 |
#6 | Faster,yolov5,Retina,yolovf| 1024A (0.131/0.110) | 512A KFLOD (0.179/0.149) | 1024A (0.135/0.114) | 1024A  (0.142/0.106) | - | 0.229/0.206 |
#7 | Faster,Retina,yolof,yolox| 1024A (0.131/0.110) | - | 1024A (0.135/0.114),1024C(0.142/0.121) | 1024A (0.142/0.106),1024B(0.135/0.122) | 1024C(0.179/0.156) | 0.215/0.165 |
#8 | Faster,Retina,yolof,yolox| 1024A (0.131/0.110) | - | 1024A (0.135/0.114),1024C(0.142/0.121) | 1024A (0.142/0.106),1024B (0.135/0.122) | 1024A(0.141/0.118),1024C(0.179/0.156) | 0.222/0.170 |    

    
* ### ì˜ˆì¸¡ ì´ë¯¸ì§€

---
## ğŸ«Discussion
 - Bioì˜ trendì¸ object detection ì„ ê³µë¶€í•˜ê¸° ìœ„í•˜ì—¬ ì„ íƒí•œ í”„ë¡œì íŠ¸
 - í•™ìŠµ dataì•ˆì—ì„œ train & validë¡œ ë‚˜ëˆ„ì§€ ì•Šê³  Group K-Foldë¥¼ ì‚¬ìš©í–ˆë˜ ì´ìœ ?
    - ì ì€ data setì— ëŒ€í•˜ì—¬ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.
    - âˆµ training/validation/test ì„¸ê°œì˜ ì§‘ë‹¨ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒë³´ë‹¤ training & testë¡œë§Œ ë¶„ë¥˜ì‹œ í•™ìŠµí•  dataê°€ ë” ë§ê²Œë˜ì–´ underfittingë“± ì„±ëŠ¥ì´ ë¯¸ë‹¬ë˜ëŠ” modelë¡œ í•™ìŠµë˜ì§€ ì•Šë„ë¡ í•¨. ë˜í•œ 1ê°œì˜ ì´ë¯¸ì§€ì— ë‹¤ì¤‘ labelì´ë¯€ë¡œ ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ í™•ì‹¤íˆ í‰ê°€í•˜ê¸°ìœ„í•´ train set & validì— í¬í•¨ëœ imageê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•˜ê¸°ìœ„í•˜ì—¬ k-foldì¤‘ì—ì„œë„ group k-foldë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ê½¤ ì˜¤ë˜ê±¸ë ¤ ì‹œê°„ìƒ k = 1 ë¡œ ì„¸íŒ…í•´ ë†“ì•˜ìŒ. (ì¦‰, kfoldë¥¼ í•˜ì§€ ì•Šê³  train:valid = 8:2ë¡œ ë°ì´í„°ì…‹ì„ ë³„ë„ë¡œ ë‚˜ëˆ  í•™ìŠµí•œ ê²ƒê³¼ ê°™ìŒ.) 
    - 10epochìœ¼ë¡œ í•™ìŠµì‹œ k=1ë¡œë§Œ ë³¸ê²ƒê³¼ k=5ë¡œ í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²°ê³¼ public scoreê°€ 0.014ì—ì„œ 0.025ë¡œ í–¥ìƒë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ë°ì´í„°ë¥¼ augmenationí•œ Bì™€ Cë„ ì œëŒ€ë¡œ k = 5ë¡œ ì„¸íŒ…í•´ì„œ í•™ìŠµí–ˆë‹¤ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì„ ë“¯ í•˜ë‹¤.

k|EPOCH|Score|EPOCH|Score
1|10e|0.014|20e|0.016
5|10e|0.025|20e|0.024
    
-  ### Zoom in augmentationì‹œ 10%ë¡œ í•œ ì´ìœ ?
    - 10%ë³´ë‹¤ ë” zoom inì„ í–ˆì„ê²½ìš° ì´ë¯¸ì§€ì˜ ê°€ì¥ìë¦¬ì— ìœ„ì¹˜í•˜ë˜ ë³‘ë³€ë“¤ì´ ì˜ë¦¬ëŠ” ê²½ìš°ë“¤ì´ ìˆì–´ì„œ ì´ë¥¼ ë§‰ê¸°ìœ„í•´ 10%ì •ë„ë§Œ zoom inì„ í•˜ì˜€ë‹¤. normalization í›„ ë‹¤ì‹œ size(512x512) ì¬ì •ì˜ì‹œ ì •ìˆ˜í™”í•¨ì—ë”°ë¼ ê°™ì€ ê°’ì„ ê°–ê²Œë˜ëŠ” ê²½ìš°ê°€ ìˆì—ˆë‹¤.

    - ë³‘ë³€ì´ ë„ˆë¬´ë„ ì‘ì•„ bboxì˜ y_maxì™€ y_minì´ ë³„ ì°¨ì´ê°€ ë‚˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸. ì´ëŸ° ë°ì´í„°ë¡œì¸í•´ í•™ìŠµì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ í•´ë‹¹ ë°ì´í„°(10ê°œ ë¯¸ë§Œ)ëŠ” ì‚­ì œí•˜ê¸°ë¡œ í•¨.

* ### Model selection

    - 1 stage model
     - YOLOX: 1 stageì—ì„œ ìœ ëª…í•˜ê³  ì†ë„ê°€ ë¹ ë¥´ê¸°ë•Œë¬¸ì— ì‚¬ìš©í•¨.
     - EfficientDet (one-stage detector paradigm ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ë¨): ì‚¬ëŒë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” YOLO v5ë³´ë‹¤ average precisionì´ ì¢‹ê¸°ë•Œë¬¸ì— ì„ íƒ.
    - 2 stage model
     - Faster R-CNN: ì´ì „ ìˆ˜ì—…ì—ì„œ ì‚¬ìš©í–ˆë˜ modelì´ 1 stageë¼ì„œ 2 stage ê³µë¶€ ê²¸ ì—¬ì „íˆ í˜„ì—­ìœ¼ë¡œ ì“°ì´ê³  ìˆëŠ” ê¸°ì´ˆì ì¸ ëª¨ë¸ì´ë¼ì„œ ì„ íƒí•˜ì˜€ìŒ.

* ### í•™ìŠµí•˜ëŠ” data ì–‘ì´ 15,000ì¥ì¸ì¤„ ì•Œì•˜ì§€ë§Œ dataë¥¼ ë¶„ì„í•œ ê²°ê³¼ ì •ìƒì¸ì„ ì œì™¸í•œ í™˜ìì˜ dataëŠ” 4,394ì¥ì´ì—ˆë‹¤.
    - ì§ˆë³‘ì„ í•™ìŠµí•´ì•¼í•˜ëŠ” modelì´ê¸°ë•Œë¬¸ì— í™˜ìì˜ dataë§Œ ê°–ê³  í•™ìŠµì„ ì‹œì¼œì•¼í•˜ëŠ”ë° dataì˜ ì–‘ì´ ë„ˆë¬´ ì ì–´ ì–‘ì„ ëŠ˜ë¦¬ê¸° ìœ„í•˜ì—¬ ì—¬ëŸ¬ augmentationì„ ì ìš©í•´ë³´ì•˜ë‹¤.
    - Augmentationì— ë”°ë¥¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ë¹„êµí•´ ë³´ê¸°ìœ„í•´ augmentationì„ ì•ˆí•œ Aê·¸ë£¹ê³¼ ê¸°ë³¸ì ì¸ augmentationì„ í•œ Bê·¸ë£¹, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¸°ë³¸ì ì¸ augmentationì™¸ ì—¬ëŸ¬ ë‹¤ì–‘í•œ ê¸°ë²•ê¹Œì§€ ì ìš©í•œ Cê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤.
ê·¸ ê²°ê³¼ 3ê°œì˜ model ëª¨ë‘ augmentationì„ í•˜ë©´ í• ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ í™•ì¸í•˜ì˜€ë‹¤.
    - Dataë‚´ì—ì„œ ëª¨ë“  labelì´ ë¹„ìŠ·í•œ ì–‘ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ì•Šê³  íŠ¹ì • labelìœ„ì£¼ë¡œ ì¡´ì¬í•˜ê³ ìˆë‹¤. ì¦‰, data imbalanceê°€ ì‹¬í•œìƒí™©.
    - Data imbalance ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„ˆë¬´ ë§ì€ ì–‘ì„ ê°–ê³ ìˆëŠ” íŠ¹ì • label(0,3,11,13)ì€ down samplingí•˜ê³  ì ì€ ì–‘ì„ ê°–ëŠ” label(1,12)ì—” ì—¬ëŸ¬ê°€ì§€ augmentationìœ¼ë¡œ up samplingí•˜ëŠ” ì‘ì—…ì„ í•˜ì˜€ë‹¤.
    - 1,12ì—ëŠ” Rotation, Flip, Zoomin, Cutmix, CLAHE, Equalization ì„ ì ìš©í•˜ê³ 
    - 0,3,11,13ì€ ì•½ 3,000ê°œë¡œ down samplingí•˜ì—¬ labelê°„ì˜ ê·¹ë‹¨ì ì¸ ì°¨ì´ê°€ ì–´ëŠì •ë„ í•´ì†Œëœ Dê·¸ë£¹ì„ ë§Œë“¤ì—ˆë‹¤. ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ê³  í•™ìŠµì†ë„ê°€ ë¹ ë¥¸ YOLOXë¡œ Dê·¸ë£¹ì„ í•™ìŠµí•œ ê²°ê³¼ Aê·¸ë£¹ì— ë¹„í•´ ì„±ëŠ¥ì´ í–¥ìƒë¨ ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆê³  ì–‘ì´ ì ì€ë°ë„ ë¶ˆêµ¬í•˜ê³  ê¸°ë³¸ 3ê°€ì§€ augmentationì„ í•œ Bê·¸ë£¹ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤.
    - í•˜ì§€ë§Œ ê¸°ë³¸ augmentationì™¸ì— ì¶”ê°€ì ì¸ augmentationì„ í–ˆë˜ Cê·¸ë£¹ë³´ë‹¤ëŠ” ì„±ëŠ¥ì´ ëœ ë‚˜ì™”ë‹¤. (ì´ëŠ” dataì˜ ì–‘ì´ 6ë°°ë‚˜ ì°¨ì´ê°€ ë‚˜ê¸°ë•Œë¬¸ì— ë‚˜ì˜¨ ê²°ê³¼)
    - Cê·¸ë£¹ì—ì„œ í›¨ì”¬ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ê²ƒì„ í†µí•´ data imbalanceë¥¼ í•´ê²°í•œê²ƒë³´ë‹¤ëŠ” dataì˜ ì–‘ì´ ì¶©ë¶„íˆ ìˆëŠ”ê²ƒì´ ì„±ëŠ¥í–¥ìƒì— ë” ë§ì€ íš¨ê³¼ê°€ ìˆìŒì„ ìœ ì¶”í•  ìˆ˜ ìˆì—ˆê³ 
    - imbalanceì™€ dataì˜ ì–‘ì„ ë™ì‹œì— í•´ê²°í•œë‹¤ë©´ ì´ë³´ë‹¤ í›¨ì”¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ ì‹¶ë‹¤.

---
## Ref
https://www.kaggle.com/code/dschettler8845/visual-in-depth-eda-vinbigdata-competition-data
https://www.kaggle.com/code/yerramvarun/pytorch-fasterrcnn-with-group-kfold-14-class
https://www.kaggle.com/code/pestipeti/vinbigdata-fasterrcnn-pytorch-inference/notebook
https://www.kaggle.com/code/pestipeti/vinbigdata-fasterrcnn-pytorch-train/notebook

