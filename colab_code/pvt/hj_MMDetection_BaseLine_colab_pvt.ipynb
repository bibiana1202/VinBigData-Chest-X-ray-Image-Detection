{"cells":[{"cell_type":"markdown","metadata":{"id":"lEvRfvpLTw_o"},"source":["\n","MMDetection tutorial을 활용하여 베이스라인을 만들었습니다.\n","\n","coco format으로 변환하는 부분은 이여름님께서 공유해주신 [코드](https://dacon.io/competitions/official/235855/codeshare/3729)를 참고했고\n","\n","데이터 정제 과정과 추론 부분은 데이콘에서 제공해 주신 [베이스라인](https://dacon.io/competitions/official/235855/codeshare/3725)을 참고했습니다.\n","\n","\n","**참고 링크** <p>\n","- [이여름님의 코드](https://dacon.io/competitions/official/235855/codeshare/3729)\n","- [데이콘 베이스라인](https://dacon.io/competitions/official/235855/codeshare/3725)\n","- [colab version tutorial](https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb)\n","- [kaggle notebook](https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer?scriptVersionId=68887943&cellId=21)\n","\n","\n","**MMDetection 관련 링크**\n","- [mmdetection github](https://github.com/open-mmlab/mmdetection)\n","- [mmdetection docs](https://mmdetection.readthedocs.io/)\n","- [model_zoo](https://mmdetection.readthedocs.io/en/latest/model_zoo.html#baselines)\n","\n","*❗❗* 코드는 모든 학습 데이터를 사용할 수 있도록 해놓았지만 출력은 일부 데이터만 사용한 결과물이며 로컬 환경과 코랩 환경을 오가며 진행했습니다."]},{"cell_type":"markdown","metadata":{"id":"RogFIyia62lO"},"source":["## Prepare data"]},{"cell_type":"markdown","metadata":{"id":"FFRFO3GV6LIp"},"source":["conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n","\n","pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/index.html\n","\n","git clone https://github.com/open-mmlab/mmdetection.git\n","\n","pip install -r requirements/build.txt\n","\n","pip install pycocotools-windows\n","\n","pip install -v -e .\n","\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"f6ZQQOUz7Hkg","executionInfo":{"status":"ok","timestamp":1666537606707,"user_tz":-540,"elapsed":839,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["# basic setup\n","import pandas as pd\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import cv2\n","import base64\n","import time\n","import math\n","import datetime\n","import os\n","import zipfile\n","import random\n","from PIL import Image\n","from io import BytesIO\n","from tqdm.notebook import tqdm\n","from glob import glob\n","\n","from collections import defaultdict\n","\n","base_dir = \"/content/project/input\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666537606707,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"qr7x8bXyzfyF","outputId":"2171f6eb-e37e-4237-d32e-eaf37fea695f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/project\n"]}],"source":["os.makedirs('./project/input', exist_ok=True)\n","os.makedirs('./project/output', exist_ok=True)\n","%cd project"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15441,"status":"ok","timestamp":1666537622146,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"9IVx9CCh6bFq","outputId":"5fa5a7ba-6c52-4c22-b8dc-e6a8422ed49f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LSbCgymk6fhe","executionInfo":{"status":"ok","timestamp":1666537641447,"user_tz":-540,"elapsed":19303,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["with zipfile.ZipFile('/content/drive/MyDrive/project/vinBigData/Chest X-ray(512).zip', 'r') as zip_ref:\n","  zip_ref.extractall('/content/project/input')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666537641447,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"mpz_faDR6LIq","outputId":"f1fe0c5c-9f2a-4b94-8ec5-5c0de5f106f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/project'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["%pwd"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xQX73XI-6rvO","executionInfo":{"status":"ok","timestamp":1666537645268,"user_tz":-540,"elapsed":3824,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["df = pd.read_csv('./input/train.csv')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666537645268,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"f_oLfWt66thS","outputId":"16abedb8-e299-412e-9e4e-22fa8d97d285"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([14,  3, 10, 11,  0, 13,  5,  8,  9,  7,  6,  4,  2,  1, 12])"]},"metadata":{},"execution_count":7}],"source":["df['class_id'].unique()"]},{"cell_type":"code","source":["# nofinding 제거 버전\n","df = pd.read_csv('./input/train.csv')\n","df = df[df['class_id'] != 14]\n","df['class_id'] = df['class_id'] + 1\n","df = df[['image_id', 'class_id', 'x_min', 'y_min', 'x_max', 'y_max']]\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"iShokgqj03-X","executionInfo":{"status":"ok","timestamp":1666537645268,"user_tz":-540,"elapsed":8,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"cdfada98-5441-4076-e99c-7e5737121652"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               image_id  class_id       x_min       y_min  \\\n","6      9a5094b2563a1ef3ff50dc5c7ff71345         4  170.092308  301.369863   \n","7      9a5094b2563a1ef3ff50dc5c7ff71345        11  440.369231  378.958904   \n","8      9a5094b2563a1ef3ff50dc5c7ff71345        12  440.369231  378.958904   \n","9      9a5094b2563a1ef3ff50dc5c7ff71345         4  170.338462  301.369863   \n","10     9a5094b2563a1ef3ff50dc5c7ff71345         4  169.600000  287.780822   \n","...                                 ...       ...         ...         ...   \n","67774  52951d7de2485aba8ed62629eee4d254        10   67.333333  256.355556   \n","67775  52951d7de2485aba8ed62629eee4d254         4  163.111111  279.288889   \n","67848  1224f07d895107573588225f692e94f9         1  250.729412  161.922261   \n","67849  1224f07d895107573588225f692e94f9         1  262.525490  155.590106   \n","67850  1224f07d895107573588225f692e94f9         1  260.015686  154.007067   \n","\n","            x_max       y_max  \n","6      406.892308  401.315068  \n","7      461.538462  436.602740  \n","8      461.538462  436.602740  \n","9      407.876923  394.301370  \n","10     410.092308  386.410959  \n","...           ...         ...  \n","67774   85.111111  268.088889  \n","67775  358.666667  336.355556  \n","67848  320.250980  223.434629  \n","67849  319.247059  221.399293  \n","67850  318.996078  218.459364  \n","\n","[36096 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-980782c3-e11e-4a17-87b9-9cdd0bce381f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>class_id</th>\n","      <th>x_min</th>\n","      <th>y_min</th>\n","      <th>x_max</th>\n","      <th>y_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n","      <td>4</td>\n","      <td>170.092308</td>\n","      <td>301.369863</td>\n","      <td>406.892308</td>\n","      <td>401.315068</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n","      <td>11</td>\n","      <td>440.369231</td>\n","      <td>378.958904</td>\n","      <td>461.538462</td>\n","      <td>436.602740</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n","      <td>12</td>\n","      <td>440.369231</td>\n","      <td>378.958904</td>\n","      <td>461.538462</td>\n","      <td>436.602740</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n","      <td>4</td>\n","      <td>170.338462</td>\n","      <td>301.369863</td>\n","      <td>407.876923</td>\n","      <td>394.301370</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n","      <td>4</td>\n","      <td>169.600000</td>\n","      <td>287.780822</td>\n","      <td>410.092308</td>\n","      <td>386.410959</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>67774</th>\n","      <td>52951d7de2485aba8ed62629eee4d254</td>\n","      <td>10</td>\n","      <td>67.333333</td>\n","      <td>256.355556</td>\n","      <td>85.111111</td>\n","      <td>268.088889</td>\n","    </tr>\n","    <tr>\n","      <th>67775</th>\n","      <td>52951d7de2485aba8ed62629eee4d254</td>\n","      <td>4</td>\n","      <td>163.111111</td>\n","      <td>279.288889</td>\n","      <td>358.666667</td>\n","      <td>336.355556</td>\n","    </tr>\n","    <tr>\n","      <th>67848</th>\n","      <td>1224f07d895107573588225f692e94f9</td>\n","      <td>1</td>\n","      <td>250.729412</td>\n","      <td>161.922261</td>\n","      <td>320.250980</td>\n","      <td>223.434629</td>\n","    </tr>\n","    <tr>\n","      <th>67849</th>\n","      <td>1224f07d895107573588225f692e94f9</td>\n","      <td>1</td>\n","      <td>262.525490</td>\n","      <td>155.590106</td>\n","      <td>319.247059</td>\n","      <td>221.399293</td>\n","    </tr>\n","    <tr>\n","      <th>67850</th>\n","      <td>1224f07d895107573588225f692e94f9</td>\n","      <td>1</td>\n","      <td>260.015686</td>\n","      <td>154.007067</td>\n","      <td>318.996078</td>\n","      <td>218.459364</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>36096 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-980782c3-e11e-4a17-87b9-9cdd0bce381f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-980782c3-e11e-4a17-87b9-9cdd0bce381f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-980782c3-e11e-4a17-87b9-9cdd0bce381f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666537645269,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"Vejc7arm_LFM","outputId":"573f7e00-aa26-4c33-9aa7-1d316372adfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["df Shape: (36096, 6)\n","No Of Classes: 14\n"]},{"output_type":"execute_result","data":{"text/plain":["36096"]},"metadata":{},"execution_count":9}],"source":["print(\"df Shape: \"+str(df.shape))\n","print(\"No Of Classes: \"+str(df[\"class_id\"].nunique()))\n","df.sort_values(by='image_id').head(10)\n","len(df)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"pvrIC3SK_vwf","executionInfo":{"status":"ok","timestamp":1666537645269,"user_tz":-540,"elapsed":5,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["def convert_to_coco(name_list, df, save_path): # 변경\n","\n","  res = defaultdict(list)\n","    \n","  categories = {\n","      'Aortic enlargement': 1,\n","      'Atelectasis': 2,\n","      'Calcification': 3,\n","      'Cardiomegaly': 4,\n","      'Consolidation': 5,\n","      'ILD': 6,\n","      'Infiltration': 7,\n","      'Lung Opacity': 8,\n","      'Nodule/Mass': 9,\n","      'Other lesion': 10,\n","      'Pleural effusion': 11,\n","      'Pleural thickening': 12,\n","      'Pneumothorax': 13,\n","      'Pulmonary fibrosis': 14\n","  }\n","    \n","  df = df[df['image_id'].isin(name_list)]\n","  names = df['image_id'].unique()\n","  n_id = 0\n","\n","  for pic_name in tqdm(names):\n","\n","    df_temp = df[df['image_id'] == pic_name]\n","    tmp = df_temp.values\n","\n","    res['images'].append({\n","        'id': pic_name,\n","        'width': 512,\n","        'height':512,\n","        'file_name': pic_name+\".png\"\n","    })\n","      \n","    for shape in tmp:\n","        x1, y1, x2, y2 = shape[2], shape[3], shape[4], shape[5]\n","        \n","        w, h = x2 - x1, y2 - y1\n","        \n","        res['annotations'].append({\n","            'id': n_id,\n","            'image_id': pic_name,\n","            'category_id': shape[1],\n","            'area': w * h,\n","            'bbox': [x1, y1, w, h],\n","            'iscrowd': 0,\n","        })\n","        n_id += 1\n","    \n","  for name, id in categories.items():\n","      res['categories'].append({\n","          'id': id,\n","          'name': name,\n","      })\n","  # return res\n","  with open(save_path, 'w') as f:\n","      json.dump(res, f)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1666537645710,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"rFHJB8WhBKHW","outputId":"a3ed94d4-1a1c-4a6e-e8ae-501c1a2b05a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["split_num : 878\n"]},{"output_type":"execute_result","data":{"text/plain":["(3516, 878, 4394)"]},"metadata":{},"execution_count":11}],"source":["random.seed(10)\n","\n","train_files = df['image_id'].unique()\n","\n","random.shuffle(train_files)\n","\n","# 8:2로 학습/검증 데이터 분리\n","split_num = int(len(train_files)*0.2)\n","print(\"split_num :\", split_num)\n","\n","train_file = train_files[split_num:]\n","valid_file = train_files[:split_num]\n","\n","len(train_file), len(valid_file),len(train_files)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4764abef8afb4802b01964fa55d50820","9e04563ede554138a83a8dae5c48e337","6a160e47e02442e8b0545888dcf5b439","bf10b0d445254ffdb3f5a9c3f20bac54","e53aa202d15b413cb27e33b2b89822e0","42635de59f024efa86ddbea2b0dd2968","c14556e47fd84935b4fc25cbc3ff07b6","c461c3ec235c47b8a4a45b5ee63f3752","d5569d8086854eddb00fb328f9300153","449f861e4c2f49d5a846f67a4337881f","85adceb7623f40d0bbc875c5aa5d1042"]},"executionInfo":{"elapsed":9092,"status":"ok","timestamp":1666537654798,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"u-d3X1l4BunK","outputId":"79749c4d-c756-4b59-a178-9499f6937420"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3516 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4764abef8afb4802b01964fa55d50820"}},"metadata":{}}],"source":["convert_to_coco(train_file, df, os.path.join(base_dir, 'train_annotations.json'))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1d7e77eec8a94414bef0c8b925393669","aebd82a928844f99b89a5c92176fb348","f4299b73183942dca9f600a24f0f1132","ff2f845f09ae48c281a81401ddf64f0c","36a8003e0f8b4b93bc9499a004a923de","2287050321f045558fb065a63b9b28cb","aee173ae879045a297b2b45d1bf3133a","f7d73715fd6f43398572612eec4211b5","19fab9a11c68408ca43e5e86404d6d8f","ba0bc81eeac048879a33a1139a4cc472","c259200282614c17810d9b531bf04c49"]},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1666537655803,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"MWjcp4UHBvri","outputId":"ceebeafd-2a16-4134-c5eb-e914c6227ed0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/878 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d7e77eec8a94414bef0c8b925393669"}},"metadata":{}}],"source":["convert_to_coco(valid_file, df, os.path.join(base_dir, 'valid_annotations.json'))"]},{"cell_type":"markdown","metadata":{"id":"UbbR6VMUH7bL"},"source":["## Environment setting"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3149,"status":"ok","timestamp":1666537658942,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"_JO7oCKbK2-f","outputId":"53f6c3ef-9dc7-43af-aea3-05e0ff6e2d5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n","Name: torch\n","Version: 1.12.1+cu113\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: typing-extensions\n","Required-by: torchvision, torchtext, torchaudio, fastai\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version\n","\n","!pip show torch"]},{"cell_type":"markdown","metadata":{"id":"rreI4H5UNN8X"},"source":["런타임 다시 시작하고 진행합니다."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2424,"status":"ok","timestamp":1666537661361,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"f55dEZ5ou9KJ","outputId":"9037b7de-e7bd-46cd-b56a-d410fa09dc6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmdetection'...\n","remote: Enumerating objects: 32083, done.\u001b[K\n","remote: Counting objects: 100% (208/208), done.\u001b[K\n","remote: Compressing objects: 100% (183/183), done.\u001b[K\n","remote: Total 32083 (delta 70), reused 100 (delta 24), pack-reused 31875\u001b[K\n","Receiving objects: 100% (32083/32083), 41.12 MiB | 37.66 MiB/s, done.\n","Resolving deltas: 100% (23033/23033), done.\n"]}],"source":["!git clone https://github.com/open-mmlab/mmdetection.git"]},{"cell_type":"code","source":["%cd ./mmdetection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGN-yRth6QlV","executionInfo":{"status":"ok","timestamp":1666537661362,"user_tz":-540,"elapsed":8,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"a6f492c6-78ba-4c0e-abb0-b8e60fe7b6e5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/project/mmdetection\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23547,"status":"ok","timestamp":1666537684905,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"dWvG1_zfABuF","outputId":"8679a838-2898-4939-a683-488c74426d81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.2-py2.py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n","Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.10)\n","Collecting rich\n","  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 10.0 MB/s \n","\u001b[?25hRequirement already satisfied: pip>=19.3 in /usr/local/lib/python3.7/dist-packages (from openmim) (21.1.3)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Collecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->model-index->openmim) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (4.1.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2022.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (3.0.4)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->openmim) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 8.8 MB/s \n","\u001b[?25hInstalling collected packages: ordered-set, commonmark, rich, model-index, colorama, openmim\n","Successfully installed colorama-0.4.5 commonmark-0.9.1 model-index-0.1.11 openmim-0.3.2 ordered-set-4.1.0 rich-12.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmdet==2.22.0\n","  Downloading mmdet-2.22.0-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mmdet==2.22.0\n","  Downloading mmdet-2.22.0.tar.gz (728 kB)\n","\u001b[K     |████████████████████████████████| 728 kB 5.1 MB/s \n","\u001b[?25hSaved /tmp/tmp0xsrjilu/mmdet-2.22.0.tar.gz\n","Successfully downloaded mmdet\n","\u001b[33mGet 'mim' extra requirements from `mminstall.txt` for mmdet 2.22.0: ['mmcv-full>=1.3.17'].\u001b[0m\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (3.2.2)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (2.0.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (1.15.0)\n","Collecting terminaltables\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (1.21.6)\n","Collecting mmcv-full>=1.3.17\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (40.6 MB)\n","\u001b[K     |████████████████████████████████| 40.6 MB 10.6 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet==2.22.0) (4.6.0.66)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet==2.22.0) (21.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet==2.22.0) (7.1.2)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet==2.22.0) (6.0)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 63.2 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.22.0) (4.1.1)\n","\u001b[33mUsing cached `mminstall.txt` for mmdet==2.22.0: /root/.cache/mim/mminstall/mmdet==2.22.0.txt\u001b[0m\n","\u001b[33mGet 'mim' extra requirements from `mminstall.txt` for mmdet 2.22.0: ['mmcv-full>=1.3.17'].\u001b[0m\n","Installing collected packages: yapf, addict, terminaltables, mmcv-full, mmdet\n","Successfully installed addict-2.4.0 mmcv-full-1.6.2 mmdet-2.22.0 terminaltables-3.1.10 yapf-0.32.0\n"]}],"source":["!pip install openmim\n","!mim install mmdet==2.22.0"]},{"cell_type":"markdown","metadata":{"id":"6ZdfnvnD8yp9"},"source":["========="]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1666537687114,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"YyK8Jr1LL_8O","outputId":"99b8e786-28cd-4d6f-9688-8c7df87c7d78"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.1+cu113 True\n","2.25.2\n","11.3\n","GCC 9.3\n"]}],"source":["# Check Pytorch installation\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","\n","# Check MMDetection installation\n","import mmdet\n","print(mmdet.__version__)\n","\n","# Check mmcv installation\n","from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n","print(get_compiling_cuda_version())\n","print(get_compiler_version())"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1666537687115,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"tW2i2iAF6LIt","outputId":"0985431c-73dc-4b6b-bc9e-d9fcd431a356"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/project/mmdetection'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["%pwd"]},{"cell_type":"code","source":["!mkdir checkpoints"],"metadata":{"id":"-TdYy7jX1a_N","executionInfo":{"status":"ok","timestamp":1666537687115,"user_tz":-540,"elapsed":17,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["%cd /content/project/mmdetection/checkpoints\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHyKdrq64mLO","executionInfo":{"status":"ok","timestamp":1666537687115,"user_tz":-540,"elapsed":16,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"c9833333-d1f6-4f6f-ab91-9cd144053526"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/project/mmdetection/checkpoints\n"]}]},{"cell_type":"code","source":["!wget -c https://download.openmmlab.com/mmdetection/v2.0/pvt/retinanet_pvtv2-b4_fpn_1x_coco/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth \\\n","      -O /content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYk0TVFO1Po7","executionInfo":{"status":"ok","timestamp":1666537726286,"user_tz":-540,"elapsed":39182,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"7b186551-8950-4d69-d912-34b7b5cb9107"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-23 15:08:06--  https://download.openmmlab.com/mmdetection/v2.0/pvt/retinanet_pvtv2-b4_fpn_1x_coco/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.43\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 289315285 (276M) [application/octet-stream]\n","Saving to: ‘/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth’\n","\n","/content/project/mm 100%[===================>] 275.91M  9.73MB/s    in 39s     \n","\n","2022-10-23 15:08:46 (7.17 MB/s) - ‘/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth’ saved [289315285/289315285]\n","\n"]}]},{"cell_type":"code","execution_count":23,"metadata":{"id":"TqQbWb4c6LIt","executionInfo":{"status":"ok","timestamp":1666537726286,"user_tz":-540,"elapsed":5,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["config = \"/content/project/mmdetection/configs/pvt/retinanet_pvtv2-b4_fpn_1x_coco.py\"\n","checkpoint = \"/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth\""]},{"cell_type":"markdown","metadata":{"id":"7GrWIJywLV-V"},"source":["## Train a detector on customized dataset\n","\n","To train a new detector, there are usually three things to do:\n","1. Support a new dataset\n","2. Modify the config\n","3. Train a new detector\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"_knbBfkiEPIr","executionInfo":{"status":"ok","timestamp":1666537726286,"user_tz":-540,"elapsed":4,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["import mmcv\n","import matplotlib.pyplot as plt\n","import copy\n","import os.path as osp\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"PwqJOpBe-bMj"},"source":["### Modify the config\n","\n","In the next step, we need to modify the config for the training.\n","To accelerate the process, we finetune a detector using a pre-trained detector."]},{"cell_type":"code","source":["!pip install mmcls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nQHw3La9Pk9","executionInfo":{"status":"ok","timestamp":1666537730385,"user_tz":-540,"elapsed":4103,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"3fe2e39f-c186-4800-bc50-00d6d988e527"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mmcls\n","  Downloading mmcls-0.24.0-py2.py3-none-any.whl (647 kB)\n","\u001b[K     |████████████████████████████████| 647 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from mmcls) (3.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcls) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcls) (1.21.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->mmcls) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->mmcls) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->mmcls) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->mmcls) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.0->mmcls) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.0->mmcls) (1.15.0)\n","Installing collected packages: mmcls\n","Successfully installed mmcls-0.24.0\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"id":"hamZrlnH-YDD","executionInfo":{"status":"ok","timestamp":1666537730386,"user_tz":-540,"elapsed":24,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["from mmcv import Config\n","import mmcls\n","cfg = Config.fromfile(config)"]},{"cell_type":"code","source":["print(f'Config:\\n{cfg.pretty_text}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWmcUeae-ZNj","executionInfo":{"status":"ok","timestamp":1666537730806,"user_tz":-540,"elapsed":443,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"db515f43-968e-4a52-fdcc-8aeca264092c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Config:\n","model = dict(\n","    type='RetinaNet',\n","    backbone=dict(\n","        type='PyramidVisionTransformerV2',\n","        embed_dims=64,\n","        num_layers=[3, 8, 27, 3],\n","        init_cfg=dict(\n","            checkpoint=\n","            'https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b4.pth'\n","        )),\n","    neck=dict(\n","        type='FPN',\n","        in_channels=[64, 128, 320, 512],\n","        out_channels=256,\n","        start_level=1,\n","        add_extra_convs='on_input',\n","        num_outs=5),\n","    bbox_head=dict(\n","        type='RetinaHead',\n","        num_classes=80,\n","        in_channels=256,\n","        stacked_convs=4,\n","        feat_channels=256,\n","        anchor_generator=dict(\n","            type='AnchorGenerator',\n","            octave_base_scale=4,\n","            scales_per_octave=3,\n","            ratios=[0.5, 1.0, 2.0],\n","            strides=[8, 16, 32, 64, 128]),\n","        bbox_coder=dict(\n","            type='DeltaXYWHBBoxCoder',\n","            target_means=[0.0, 0.0, 0.0, 0.0],\n","            target_stds=[1.0, 1.0, 1.0, 1.0]),\n","        loss_cls=dict(\n","            type='FocalLoss',\n","            use_sigmoid=True,\n","            gamma=2.0,\n","            alpha=0.25,\n","            loss_weight=1.0),\n","        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n","    train_cfg=dict(\n","        assigner=dict(\n","            type='MaxIoUAssigner',\n","            pos_iou_thr=0.5,\n","            neg_iou_thr=0.4,\n","            min_pos_iou=0,\n","            ignore_iof_thr=-1),\n","        allowed_border=-1,\n","        pos_weight=-1,\n","        debug=False),\n","    test_cfg=dict(\n","        nms_pre=1000,\n","        min_bbox_size=0,\n","        score_thr=0.05,\n","        nms=dict(type='nms', iou_threshold=0.5),\n","        max_per_img=100))\n","dataset_type = 'CocoDataset'\n","data_root = 'data/coco/'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1333, 800),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=1,\n","    train=dict(\n","        type='CocoDataset',\n","        ann_file='data/coco/annotations/instances_train2017.json',\n","        img_prefix='data/coco/train2017/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","            dict(type='RandomFlip', flip_ratio=0.5),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ]),\n","    val=dict(\n","        type='CocoDataset',\n","        ann_file='data/coco/annotations/instances_val2017.json',\n","        img_prefix='data/coco/val2017/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict(\n","        type='CocoDataset',\n","        ann_file='data/coco/annotations/instances_val2017.json',\n","        img_prefix='data/coco/val2017/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]))\n","evaluation = dict(interval=1, metric='bbox')\n","optimizer = dict(type='AdamW', lr=7.142857142857143e-05, weight_decay=0.0001)\n","optimizer_config = dict(grad_clip=None)\n","lr_config = dict(\n","    policy='step',\n","    warmup='linear',\n","    warmup_iters=500,\n","    warmup_ratio=0.001,\n","    step=[8, 11])\n","runner = dict(type='EpochBasedRunner', max_epochs=12)\n","checkpoint_config = dict(interval=1)\n","log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n","custom_hooks = [dict(type='NumClassCheckHook')]\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","opencv_num_threads = 0\n","mp_start_method = 'fork'\n","auto_scale_lr = dict(enable=False, base_batch_size=8)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HntziLGq-92Z"},"source":["Given a config that trains a Faster R-CNN on COCO dataset, we need to modify some values to use it for training Faster R-CNN on KITTI dataset."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"y4eCt_Ub6LIu","executionInfo":{"status":"ok","timestamp":1666537732510,"user_tz":-540,"elapsed":1708,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"outputs":[],"source":["from mmdet.apis import set_random_seed\n","\n","base_path = '/content/project/input' # base_dir과 같습니다.\n","\n","# Set up working dir to save files and logs.\n","cfg.work_dir = '/content/drive/MyDrive/project/vinBigData/pvt/1'\n","\n","EPOCHS= 36\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1666537733506,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"qb0FGH8aIrpj","outputId":"24a99c83-ef0a-4be0-8b4d-970fd2c2e211"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config:\n","model = dict(\n","    type='RetinaNet',\n","    backbone=dict(\n","        type='PyramidVisionTransformerV2',\n","        embed_dims=64,\n","        num_layers=[3, 8, 27, 3],\n","        init_cfg=dict(\n","            checkpoint=\n","            '/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth'\n","        )),\n","    neck=dict(\n","        type='FPN',\n","        in_channels=[64, 128, 320, 512],\n","        out_channels=256,\n","        start_level=1,\n","        add_extra_convs='on_input',\n","        num_outs=5),\n","    bbox_head=dict(\n","        type='RetinaHead',\n","        num_classes=14,\n","        in_channels=256,\n","        stacked_convs=4,\n","        feat_channels=256,\n","        anchor_generator=dict(\n","            type='AnchorGenerator',\n","            octave_base_scale=4,\n","            scales_per_octave=3,\n","            ratios=[0.5, 1.0, 2.0],\n","            strides=[8, 16, 32, 64, 128]),\n","        bbox_coder=dict(\n","            type='DeltaXYWHBBoxCoder',\n","            target_means=[0.0, 0.0, 0.0, 0.0],\n","            target_stds=[1.0, 1.0, 1.0, 1.0]),\n","        loss_cls=dict(\n","            type='FocalLoss',\n","            use_sigmoid=True,\n","            gamma=2.0,\n","            alpha=0.25,\n","            loss_weight=1.0),\n","        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n","    train_cfg=dict(\n","        assigner=dict(\n","            type='MaxIoUAssigner',\n","            pos_iou_thr=0.5,\n","            neg_iou_thr=0.4,\n","            min_pos_iou=0,\n","            ignore_iof_thr=-1),\n","        allowed_border=-1,\n","        pos_weight=-1,\n","        debug=False),\n","    test_cfg=dict(\n","        nms_pre=1000,\n","        min_bbox_size=0,\n","        score_thr=0.05,\n","        nms=dict(type='nms', iou_threshold=0.5),\n","        max_per_img=100))\n","dataset_type = 'CocoDataset'\n","data_root = '/content/project/input'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1333, 800),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=8,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='CocoDataset',\n","        ann_file='train_annotations.json',\n","        img_prefix='train',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","            dict(type='RandomFlip', flip_ratio=0.5),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ],\n","        data_root='/content/project/input',\n","        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n","                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n","                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n","                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n","                 'Pulmonary fibrosis')),\n","    val=dict(\n","        type='CocoDataset',\n","        ann_file='valid_annotations.json',\n","        img_prefix='train',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/project/input',\n","        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n","                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n","                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n","                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n","                 'Pulmonary fibrosis')),\n","    test=dict(\n","        type='CocoDataset',\n","        ann_file='valid_annotations.json',\n","        img_prefix='test',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/project/input',\n","        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n","                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n","                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n","                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n","                 'Pulmonary fibrosis')))\n","evaluation = dict(interval=1, metric='bbox')\n","optimizer = dict(type='AdamW', lr=0.0003, weight_decay=0.0001)\n","optimizer_config = dict(grad_clip=None)\n","lr_config = dict(\n","    policy='step',\n","    warmup=None,\n","    warmup_iters=500,\n","    warmup_ratio=0.001,\n","    step=[8, 11])\n","runner = dict(type='EpochBasedRunner', max_epochs=36)\n","checkpoint_config = dict(interval=1)\n","log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n","custom_hooks = [dict(type='NumClassCheckHook')]\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = '/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","opencv_num_threads = 0\n","mp_start_method = 'fork'\n","auto_scale_lr = dict(enable=False, base_batch_size=8)\n","work_dir = '/content/drive/MyDrive/project/vinBigData/pvt/1'\n","checkpoint_file = '/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth'\n","seed = 0\n","gpu_ids = range(0, 1)\n","device = 'cuda'\n","pretrained = '/content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth'\n","\n"]}],"source":["train_anno = \"train_annotations.json\" # 출력은 \"train_partial_annotations.json\"\n","valid_anno = \"valid_annotations.json\" # 출력은 \"valid_partial_annotations.json\"\n","test_anno = \"valid_annotations.json\" # 출력은 \"valid_partial_annotations.json\"\n","\n","train_img = \"train\" # 출력은 \"train_100000\"\n","valid_img = 'train'\n","test_img =  \"test\" # 출력은 \"train_100000\"\n","\n","\n","\n","# Modify dataset type and path\n","cfg.dataset_type = 'CocoDataset'\n","cfg.data_root = base_path\n","\n","#train\n","cfg.data.train.type = 'CocoDataset'\n","cfg.data.train.data_root = base_path\n","cfg.data.train.ann_file = train_anno\n","cfg.data.train.img_prefix = train_img\n","\n","#valid\n","cfg.data.val.type = 'CocoDataset'\n","cfg.data.val.data_root = base_path\n","cfg.data.val.ann_file = valid_anno\n","cfg.data.val.img_prefix = valid_img\n","\n","#test\n","cfg.data.test.type = 'CocoDataset'\n","cfg.data.test.data_root = base_path\n","cfg.data.test.ann_file = test_anno\n","cfg.data.test.img_prefix = test_img\n","\n","\n","\n","cfg.data.samples_per_gpu = 8\n","cfg.data.workers_per_gpu = 2\n","\n","classes = (\n","    'Aortic enlargement',\n","    'Atelectasis',\n","    'Calcification',\n","    'Cardiomegaly',\n","    'Consolidation',\n","    'ILD',\n","    'Infiltration',\n","    'Lung Opacity',\n","    'Nodule/Mass',\n","    'Other lesion',\n","    'Pleural effusion',\n","    'Pleural thickening',\n","    'Pneumothorax',\n","    'Pulmonary fibrosis',\n","    )\n","\n","cfg.data.train.classes = classes\n","cfg.data.val.classes = classes\n","cfg.data.test.classes = classes\n","\n","\n","# modify num classes of the model in box head\n","cfg.model.bbox_head['num_classes'] =14\n","\n","# We can still use the pre-trained Mask RCNN model though we do not need to\n","# use the mask branch\n","\n","cfg.load_from = checkpoint\n","cfg.checkpoint_file = checkpoint\n","#resume-from : weight와 optimizer 상태 모두 로드 및 epoch도 지정된 checkpoint에서 상속\n","cfg.resume_from = None\n","\n","\n","# The original learning rate (LR) is set for 8-GPU training.\n","# We divide it by 8 since we only use one GPU.\n","cfg.optimizer = dict(type='AdamW', lr=0.0003, weight_decay=0.0001)\n","#cfg.optimizer.lr = 0.02 / 8 # 0.0025\n","# learning rate\n","cfg.lr_config.warmup = None\n","\n","# 에폭 수 조절\n","cfg.runner = dict(type='EpochBasedRunner', max_epochs=EPOCHS)\n","\n","cfg.log_config.interval = 10\n","\n","# Change the evaluation metric since we use customized dataset.\n","#COCO dataset은 mmdetection에서 mAP metric을 지원하지 않아 VOC로 테스트\n","cfg.evaluation.metric = 'bbox'\n","# We can set the evaluation interval to reduce the evaluation times\n","cfg.evaluation.interval = 1\n","# We can set the checkpoint saving interval to reduce the storage cost\n","cfg.checkpoint_config.interval = 1\n","\n","# Set seed thus the results are more reproducible\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","\n","cfg.device='cuda'\n","\n","\n","cfg.model.backbone.init_cfg.checkpoint =checkpoint\n","cfg.pretrained = checkpoint\n","\n","# We can initialize the logger for training and have a look\n","# at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')\n"]},{"cell_type":"markdown","metadata":{"id":"111W_oZV_3wa"},"source":["### Train a new detector\n","\n","Finally, lets initialize the dataset and detector, then train a new detector!"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1666537734100,"user":{"displayName":"박혜정","userId":"13305762505933234909"},"user_tz":-540},"id":"Aahl3Vqo6LIu","outputId":"5b989e3c-29cd-467b-d5c6-fff034a6725e"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.22s)\n","creating index...\n","index created!\n","[\n","CocoDataset Train dataset with number of images 3516, and instance counts: \n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n","| category               | count | category                | count | category          | count | category                | count | category          | count |\n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n","| 0 [Aortic enlargement] | 5793  | 1 [Atelectasis]         | 209   | 2 [Calcification] | 808   | 3 [Cardiomegaly]        | 4357  | 4 [Consolidation] | 441   |\n","| 5 [ILD]                | 806   | 6 [Infiltration]        | 1042  | 7 [Lung Opacity]  | 1980  | 8 [Nodule/Mass]         | 2058  | 9 [Other lesion]  | 1742  |\n","| 10 [Pleural effusion]  | 1921  | 11 [Pleural thickening] | 3834  | 12 [Pneumothorax] | 186   | 13 [Pulmonary fibrosis] | 3689  | -1 background     | 0     |\n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+]\n"]}],"source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","\n","\n","# Build dataset\n","datasets = [build_dataset(cfg.data.train)]\n","print(datasets)"]},{"cell_type":"code","source":["# Build the detector\n","model = build_detector(\n","    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n","\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES\n","\n","# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n"],"metadata":{"id":"uciRpCRkbhEW","executionInfo":{"status":"ok","timestamp":1666537735158,"user_tz":-540,"elapsed":1060,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# train\n","train_detector(model, datasets, cfg, distributed=False, validate=True)"],"metadata":{"id":"wkWzDXeia1ib","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"20df943c-a85e-4c4c-f32e-d16750b88a9a","executionInfo":{"status":"error","timestamp":1666537748754,"user_tz":-540,"elapsed":13604,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-10-23 15:08:58,433 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n","2022-10-23 15:08:58,484 - mmdet - INFO - load checkpoint from local path: /content/project/mmdetection/checkpoints/retinanet_pvtv2-b4_fpn_1x_coco_20210901_170151-83795c86.pth\n"]},{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 15:08:58,793 - mmdet - WARNING - The model and loaded state dict do not match exactly\n","\n","size mismatch for bbox_head.retina_cls.weight: copying a param with shape torch.Size([720, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([126, 256, 3, 3]).\n","size mismatch for bbox_head.retina_cls.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([126]).\n","2022-10-23 15:08:58,800 - mmdet - INFO - Start running, host: root@1451e743daa6, work_dir: /content/drive/MyDrive/project/vinBigData/pvt/1\n","2022-10-23 15:08:58,801 - mmdet - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-10-23 15:08:58,802 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs\n","2022-10-23 15:08:58,803 - mmdet - INFO - Checkpoints will be saved to /content/drive/MyDrive/project/vinBigData/pvt/1 by HardDiskBackend.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-c0ac75ba9718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/project/mmdetection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             outputs = self.model.train_step(data_batch, self.optimizer,\n\u001b[0;32m---> 32\u001b[0;31m                                             **kwargs)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/parallel/data_parallel.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data, optimizer)\u001b[0m\n\u001b[1;32m    246\u001b[0m                   \u001b[0maveraging\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                                 f'method of those classes {supported_types}')\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSingleStageDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,\n\u001b[1;32m     84\u001b[0m                                               gt_labels, gt_bboxes_ignore)\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36mextract_feat\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;34m\"\"\"Directly extract features from the backbone+neck.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_neck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/backbones/pvt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlc_to_nchw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/backbones/pvt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hw_shape)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/project/mmdetection/mmdet/models/backbones/pvt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hw_shape, identity)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlc_to_nchw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnchw_to_nlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midentity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproximate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 39.59 GiB total capacity; 37.45 GiB already allocated; 96.19 MiB free; 37.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["PATH=f'/content/drive/MyDrive/project/vinBigData/swin/model/epoch_{EPOCHS}swin.pt'\n","torch.save(model, PATH)"],"metadata":{"id":"VPo8vG8WNNDq","executionInfo":{"status":"aborted","timestamp":1666537748755,"user_tz":-540,"elapsed":7,"user":{"displayName":"박혜정","userId":"13305762505933234909"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","!python tools/deployment/mmdet2torchserve.py ${CONFIG_FILE} ${CHECKPOINT_FILE} \\\n","--output-folder ${MODEL_STORE} \\\n","--model-name ${MODEL_NAME}\n","'''"],"metadata":{"id":"22A0FLNqYhH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습 이어서 하기"],"metadata":{"id":"ivr3KKZwf7VP"}},{"cell_type":"code","source":["# model로는 이어서 안됨, test 추론 할때 사용\n","# torch.save(model,'/content/drive/MyDrive/vinBigData/faster/model.pt')\n","# checkpoint로 이어서 가능\n","#resume-from : weight와 optimizer 상태 모두 로드 및 epoch도 지정된 checkpoint에서 상속\n","cfg.resume_from = '/content/drive/MyDrive/project/vinBigData/retina/1/epoch_18.pth'\n","cfg.load_from = None\n","EPOCHS = 20\n","# 에폭 수 조절\n","cfg.runner = dict(type='EpochBasedRunner', max_epochs=EPOCHS)\n"],"metadata":{"id":"gyLsLIT2bsB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","\n","\n","# Build dataset\n","datasets = [build_dataset(cfg.data.train)]\n","print(datasets)\n","\n","# Build the detector\n","model = build_detector(\n","    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n","\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES\n","\n","# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","\n","# train!!!\n","train_detector(model, datasets, cfg, distributed=False, validate=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jg1yvXzcTlj","executionInfo":{"status":"ok","timestamp":1666526623595,"user_tz":-540,"elapsed":2113714,"user":{"displayName":"박혜정","userId":"13305762505933234909"}},"outputId":"e755cffe-6ec5-4050-a64a-068329f0802b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.10s)\n","creating index...\n","index created!\n","[\n","CocoDataset Train dataset with number of images 3516, and instance counts: \n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n","| category               | count | category                | count | category          | count | category                | count | category          | count |\n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n","| 0 [Aortic enlargement] | 5793  | 1 [Atelectasis]         | 209   | 2 [Calcification] | 808   | 3 [Cardiomegaly]        | 4357  | 4 [Consolidation] | 441   |\n","| 5 [ILD]                | 806   | 6 [Infiltration]        | 1042  | 7 [Lung Opacity]  | 1980  | 8 [Nodule/Mass]         | 2058  | 9 [Other lesion]  | 1742  |\n","| 10 [Pleural effusion]  | 1921  | 11 [Pleural thickening] | 3834  | 12 [Pneumothorax] | 186   | 13 [Pulmonary fibrosis] | 3689  | -1 background     | 0     |\n","+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+]\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 11:28:30,179 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n","2022-10-23 11:28:30,223 - mmdet - INFO - load checkpoint from local path: /content/drive/MyDrive/project/vinBigData/retina/1/epoch_18.pth\n"]},{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 11:28:50,305 - mmdet - INFO - resumed epoch 18, iter 7920\n","2022-10-23 11:28:50,309 - mmdet - INFO - Start running, host: root@588d36817ca1, work_dir: /content/drive/MyDrive/project/vinBigData/retina/1\n","2022-10-23 11:28:50,310 - mmdet - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-10-23 11:28:50,312 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n","2022-10-23 11:28:50,313 - mmdet - INFO - Checkpoints will be saved to /content/drive/MyDrive/project/vinBigData/retina/1 by HardDiskBackend.\n","2022-10-23 11:29:13,715 - mmdet - INFO - Epoch [19][10/440]\tlr: 3.000e-05, eta: 0:33:55, time: 2.339, data_time: 0.259, memory: 11233, loss_cls: 0.2476, loss_bbox: 0.3296, loss: 0.5772\n","2022-10-23 11:29:35,315 - mmdet - INFO - Epoch [19][20/440]\tlr: 3.000e-05, eta: 0:32:14, time: 2.160, data_time: 0.015, memory: 11233, loss_cls: 0.2636, loss_bbox: 0.3292, loss: 0.5928\n","2022-10-23 11:29:56,496 - mmdet - INFO - Epoch [19][30/440]\tlr: 3.000e-05, eta: 0:31:14, time: 2.118, data_time: 0.016, memory: 11233, loss_cls: 0.2175, loss_bbox: 0.3104, loss: 0.5279\n","2022-10-23 11:30:17,392 - mmdet - INFO - Epoch [19][40/440]\tlr: 3.000e-05, eta: 0:30:28, time: 2.090, data_time: 0.015, memory: 11233, loss_cls: 0.2390, loss_bbox: 0.3183, loss: 0.5573\n","2022-10-23 11:30:38,407 - mmdet - INFO - Epoch [19][50/440]\tlr: 3.000e-05, eta: 0:29:54, time: 2.101, data_time: 0.015, memory: 11233, loss_cls: 0.2320, loss_bbox: 0.3195, loss: 0.5516\n","2022-10-23 11:30:59,537 - mmdet - INFO - Epoch [19][60/440]\tlr: 3.000e-05, eta: 0:29:25, time: 2.113, data_time: 0.016, memory: 11233, loss_cls: 0.2293, loss_bbox: 0.3142, loss: 0.5435\n","2022-10-23 11:31:20,689 - mmdet - INFO - Epoch [19][70/440]\tlr: 3.000e-05, eta: 0:28:59, time: 2.115, data_time: 0.015, memory: 11233, loss_cls: 0.2426, loss_bbox: 0.3284, loss: 0.5710\n","2022-10-23 11:31:41,781 - mmdet - INFO - Epoch [19][80/440]\tlr: 3.000e-05, eta: 0:28:34, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2700, loss_bbox: 0.3368, loss: 0.6068\n","2022-10-23 11:32:02,877 - mmdet - INFO - Epoch [19][90/440]\tlr: 3.000e-05, eta: 0:28:10, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2826, loss_bbox: 0.3438, loss: 0.6264\n","2022-10-23 11:32:23,974 - mmdet - INFO - Epoch [19][100/440]\tlr: 3.000e-05, eta: 0:27:46, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2395, loss_bbox: 0.3205, loss: 0.5600\n","2022-10-23 11:32:45,066 - mmdet - INFO - Epoch [19][110/440]\tlr: 3.000e-05, eta: 0:27:23, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2476, loss_bbox: 0.3206, loss: 0.5682\n","2022-10-23 11:33:06,188 - mmdet - INFO - Epoch [19][120/440]\tlr: 3.000e-05, eta: 0:27:00, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2352, loss_bbox: 0.3069, loss: 0.5421\n","2022-10-23 11:33:27,314 - mmdet - INFO - Epoch [19][130/440]\tlr: 3.000e-05, eta: 0:26:38, time: 2.113, data_time: 0.015, memory: 11233, loss_cls: 0.2511, loss_bbox: 0.3271, loss: 0.5782\n","2022-10-23 11:33:48,423 - mmdet - INFO - Epoch [19][140/440]\tlr: 3.000e-05, eta: 0:26:15, time: 2.111, data_time: 0.015, memory: 11233, loss_cls: 0.2451, loss_bbox: 0.3296, loss: 0.5748\n","2022-10-23 11:34:09,512 - mmdet - INFO - Epoch [19][150/440]\tlr: 3.000e-05, eta: 0:25:53, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2165, loss_bbox: 0.3091, loss: 0.5256\n","2022-10-23 11:34:30,611 - mmdet - INFO - Epoch [19][160/440]\tlr: 3.000e-05, eta: 0:25:31, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2474, loss_bbox: 0.3262, loss: 0.5736\n","2022-10-23 11:34:51,701 - mmdet - INFO - Epoch [19][170/440]\tlr: 3.000e-05, eta: 0:25:09, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2482, loss_bbox: 0.3313, loss: 0.5794\n","2022-10-23 11:35:12,770 - mmdet - INFO - Epoch [19][180/440]\tlr: 3.000e-05, eta: 0:24:47, time: 2.107, data_time: 0.015, memory: 11233, loss_cls: 0.2565, loss_bbox: 0.3193, loss: 0.5758\n","2022-10-23 11:35:33,873 - mmdet - INFO - Epoch [19][190/440]\tlr: 3.000e-05, eta: 0:24:25, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2576, loss_bbox: 0.3253, loss: 0.5828\n","2022-10-23 11:35:54,990 - mmdet - INFO - Epoch [19][200/440]\tlr: 3.000e-05, eta: 0:24:03, time: 2.112, data_time: 0.015, memory: 11233, loss_cls: 0.2219, loss_bbox: 0.3110, loss: 0.5328\n","2022-10-23 11:36:16,086 - mmdet - INFO - Epoch [19][210/440]\tlr: 3.000e-05, eta: 0:23:42, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2253, loss_bbox: 0.3265, loss: 0.5518\n","2022-10-23 11:36:37,203 - mmdet - INFO - Epoch [19][220/440]\tlr: 3.000e-05, eta: 0:23:20, time: 2.112, data_time: 0.017, memory: 11233, loss_cls: 0.2881, loss_bbox: 0.3472, loss: 0.6354\n","2022-10-23 11:36:58,317 - mmdet - INFO - Epoch [19][230/440]\tlr: 3.000e-05, eta: 0:22:59, time: 2.111, data_time: 0.015, memory: 11233, loss_cls: 0.2390, loss_bbox: 0.3091, loss: 0.5482\n","2022-10-23 11:37:19,407 - mmdet - INFO - Epoch [19][240/440]\tlr: 3.000e-05, eta: 0:22:37, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2499, loss_bbox: 0.3287, loss: 0.5786\n","2022-10-23 11:37:40,504 - mmdet - INFO - Epoch [19][250/440]\tlr: 3.000e-05, eta: 0:22:16, time: 2.110, data_time: 0.017, memory: 11233, loss_cls: 0.2480, loss_bbox: 0.3163, loss: 0.5643\n","2022-10-23 11:38:01,616 - mmdet - INFO - Epoch [19][260/440]\tlr: 3.000e-05, eta: 0:21:54, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2602, loss_bbox: 0.3364, loss: 0.5965\n","2022-10-23 11:38:22,714 - mmdet - INFO - Epoch [19][270/440]\tlr: 3.000e-05, eta: 0:21:33, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2501, loss_bbox: 0.3228, loss: 0.5729\n","2022-10-23 11:38:43,804 - mmdet - INFO - Epoch [19][280/440]\tlr: 3.000e-05, eta: 0:21:11, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2408, loss_bbox: 0.3067, loss: 0.5475\n","2022-10-23 11:39:04,924 - mmdet - INFO - Epoch [19][290/440]\tlr: 3.000e-05, eta: 0:20:50, time: 2.112, data_time: 0.015, memory: 11233, loss_cls: 0.2740, loss_bbox: 0.3368, loss: 0.6108\n","2022-10-23 11:39:26,035 - mmdet - INFO - Epoch [19][300/440]\tlr: 3.000e-05, eta: 0:20:29, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2784, loss_bbox: 0.3320, loss: 0.6104\n","2022-10-23 11:39:47,124 - mmdet - INFO - Epoch [19][310/440]\tlr: 3.000e-05, eta: 0:20:07, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2564, loss_bbox: 0.3331, loss: 0.5895\n","2022-10-23 11:40:08,217 - mmdet - INFO - Epoch [19][320/440]\tlr: 3.000e-05, eta: 0:19:46, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2521, loss_bbox: 0.3291, loss: 0.5812\n","2022-10-23 11:40:29,305 - mmdet - INFO - Epoch [19][330/440]\tlr: 3.000e-05, eta: 0:19:24, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2544, loss_bbox: 0.3250, loss: 0.5794\n","2022-10-23 11:40:50,409 - mmdet - INFO - Epoch [19][340/440]\tlr: 3.000e-05, eta: 0:19:03, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2346, loss_bbox: 0.3249, loss: 0.5596\n","2022-10-23 11:41:11,500 - mmdet - INFO - Epoch [19][350/440]\tlr: 3.000e-05, eta: 0:18:42, time: 2.109, data_time: 0.017, memory: 11233, loss_cls: 0.2633, loss_bbox: 0.3328, loss: 0.5961\n","2022-10-23 11:41:32,596 - mmdet - INFO - Epoch [19][360/440]\tlr: 3.000e-05, eta: 0:18:21, time: 2.110, data_time: 0.017, memory: 11233, loss_cls: 0.2782, loss_bbox: 0.3363, loss: 0.6145\n","2022-10-23 11:41:53,689 - mmdet - INFO - Epoch [19][370/440]\tlr: 3.000e-05, eta: 0:17:59, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2676, loss_bbox: 0.3508, loss: 0.6184\n","2022-10-23 11:42:14,808 - mmdet - INFO - Epoch [19][380/440]\tlr: 3.000e-05, eta: 0:17:38, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2583, loss_bbox: 0.3315, loss: 0.5899\n","2022-10-23 11:42:35,923 - mmdet - INFO - Epoch [19][390/440]\tlr: 3.000e-05, eta: 0:17:17, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2389, loss_bbox: 0.3176, loss: 0.5565\n","2022-10-23 11:42:57,052 - mmdet - INFO - Epoch [19][400/440]\tlr: 3.000e-05, eta: 0:16:56, time: 2.113, data_time: 0.017, memory: 11233, loss_cls: 0.2445, loss_bbox: 0.3208, loss: 0.5652\n","2022-10-23 11:43:18,144 - mmdet - INFO - Epoch [19][410/440]\tlr: 3.000e-05, eta: 0:16:34, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2571, loss_bbox: 0.3297, loss: 0.5868\n","2022-10-23 11:43:39,282 - mmdet - INFO - Epoch [19][420/440]\tlr: 3.000e-05, eta: 0:16:13, time: 2.114, data_time: 0.017, memory: 11233, loss_cls: 0.2530, loss_bbox: 0.3255, loss: 0.5785\n","2022-10-23 11:44:00,421 - mmdet - INFO - Epoch [19][430/440]\tlr: 3.000e-05, eta: 0:15:52, time: 2.114, data_time: 0.016, memory: 11233, loss_cls: 0.2886, loss_bbox: 0.3548, loss: 0.6435\n","2022-10-23 11:44:21,540 - mmdet - INFO - Epoch [19][440/440]\tlr: 3.000e-05, eta: 0:15:31, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2658, loss_bbox: 0.3401, loss: 0.6059\n","2022-10-23 11:44:21,620 - mmdet - INFO - Saving checkpoint at 19 epochs\n"]},{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 878/878, 8.7 task/s, elapsed: 101s, ETA:     0s"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 11:46:07,434 - mmdet - INFO - Evaluating bbox...\n"]},{"output_type":"stream","name":"stdout","text":["Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.18s).\n","Accumulating evaluation results...\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 11:46:15,527 - mmdet - INFO - \n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.284\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.082\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.040\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.106\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.144\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.341\n","\n","2022-10-23 11:46:15,642 - mmdet - INFO - Epoch(val) [19][878]\tbbox_mAP: 0.1140, bbox_mAP_50: 0.2840, bbox_mAP_75: 0.0820, bbox_mAP_s: 0.0400, bbox_mAP_m: 0.1060, bbox_mAP_l: 0.1440, bbox_mAP_copypaste: 0.114 0.284 0.082 0.040 0.106 0.144\n"]},{"output_type":"stream","name":"stdout","text":["DONE (t=2.17s).\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 11:46:39,163 - mmdet - INFO - Epoch [20][10/440]\tlr: 3.000e-05, eta: 0:15:12, time: 2.350, data_time: 0.264, memory: 11233, loss_cls: 0.2441, loss_bbox: 0.3254, loss: 0.5696\n","2022-10-23 11:47:00,781 - mmdet - INFO - Epoch [20][20/440]\tlr: 3.000e-05, eta: 0:14:51, time: 2.162, data_time: 0.015, memory: 11233, loss_cls: 0.2483, loss_bbox: 0.3198, loss: 0.5680\n","2022-10-23 11:47:21,981 - mmdet - INFO - Epoch [20][30/440]\tlr: 3.000e-05, eta: 0:14:30, time: 2.120, data_time: 0.015, memory: 11233, loss_cls: 0.2305, loss_bbox: 0.3293, loss: 0.5598\n","2022-10-23 11:47:42,926 - mmdet - INFO - Epoch [20][40/440]\tlr: 3.000e-05, eta: 0:14:08, time: 2.094, data_time: 0.015, memory: 11233, loss_cls: 0.2297, loss_bbox: 0.3163, loss: 0.5460\n","2022-10-23 11:48:03,924 - mmdet - INFO - Epoch [20][50/440]\tlr: 3.000e-05, eta: 0:13:47, time: 2.100, data_time: 0.015, memory: 11233, loss_cls: 0.2470, loss_bbox: 0.3222, loss: 0.5692\n","2022-10-23 11:48:25,109 - mmdet - INFO - Epoch [20][60/440]\tlr: 3.000e-05, eta: 0:13:26, time: 2.118, data_time: 0.016, memory: 11233, loss_cls: 0.2346, loss_bbox: 0.3160, loss: 0.5505\n","2022-10-23 11:48:46,259 - mmdet - INFO - Epoch [20][70/440]\tlr: 3.000e-05, eta: 0:13:04, time: 2.115, data_time: 0.016, memory: 11233, loss_cls: 0.2323, loss_bbox: 0.3175, loss: 0.5499\n","2022-10-23 11:49:07,355 - mmdet - INFO - Epoch [20][80/440]\tlr: 3.000e-05, eta: 0:12:43, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2461, loss_bbox: 0.3261, loss: 0.5722\n","2022-10-23 11:49:28,420 - mmdet - INFO - Epoch [20][90/440]\tlr: 3.000e-05, eta: 0:12:22, time: 2.107, data_time: 0.015, memory: 11233, loss_cls: 0.2508, loss_bbox: 0.3198, loss: 0.5706\n","2022-10-23 11:49:49,525 - mmdet - INFO - Epoch [20][100/440]\tlr: 3.000e-05, eta: 0:12:00, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2323, loss_bbox: 0.3073, loss: 0.5396\n","2022-10-23 11:50:10,619 - mmdet - INFO - Epoch [20][110/440]\tlr: 3.000e-05, eta: 0:11:39, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2235, loss_bbox: 0.3127, loss: 0.5363\n","2022-10-23 11:50:31,743 - mmdet - INFO - Epoch [20][120/440]\tlr: 3.000e-05, eta: 0:11:18, time: 2.112, data_time: 0.015, memory: 11233, loss_cls: 0.2467, loss_bbox: 0.3177, loss: 0.5644\n","2022-10-23 11:50:52,851 - mmdet - INFO - Epoch [20][130/440]\tlr: 3.000e-05, eta: 0:10:57, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2273, loss_bbox: 0.3150, loss: 0.5423\n","2022-10-23 11:51:13,951 - mmdet - INFO - Epoch [20][140/440]\tlr: 3.000e-05, eta: 0:10:35, time: 2.110, data_time: 0.015, memory: 11233, loss_cls: 0.2280, loss_bbox: 0.3174, loss: 0.5453\n","2022-10-23 11:51:35,068 - mmdet - INFO - Epoch [20][150/440]\tlr: 3.000e-05, eta: 0:10:14, time: 2.112, data_time: 0.015, memory: 11233, loss_cls: 0.2536, loss_bbox: 0.3130, loss: 0.5666\n","2022-10-23 11:51:56,170 - mmdet - INFO - Epoch [20][160/440]\tlr: 3.000e-05, eta: 0:09:53, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2350, loss_bbox: 0.3122, loss: 0.5472\n","2022-10-23 11:52:17,300 - mmdet - INFO - Epoch [20][170/440]\tlr: 3.000e-05, eta: 0:09:32, time: 2.113, data_time: 0.016, memory: 11233, loss_cls: 0.2464, loss_bbox: 0.3108, loss: 0.5573\n","2022-10-23 11:52:38,436 - mmdet - INFO - Epoch [20][180/440]\tlr: 3.000e-05, eta: 0:09:11, time: 2.114, data_time: 0.015, memory: 11233, loss_cls: 0.2243, loss_bbox: 0.3172, loss: 0.5414\n","2022-10-23 11:52:59,526 - mmdet - INFO - Epoch [20][190/440]\tlr: 3.000e-05, eta: 0:08:49, time: 2.109, data_time: 0.015, memory: 11233, loss_cls: 0.2229, loss_bbox: 0.3186, loss: 0.5416\n","2022-10-23 11:53:20,640 - mmdet - INFO - Epoch [20][200/440]\tlr: 3.000e-05, eta: 0:08:28, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2314, loss_bbox: 0.3091, loss: 0.5405\n","2022-10-23 11:53:41,765 - mmdet - INFO - Epoch [20][210/440]\tlr: 3.000e-05, eta: 0:08:07, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2617, loss_bbox: 0.3218, loss: 0.5835\n","2022-10-23 11:54:02,882 - mmdet - INFO - Epoch [20][220/440]\tlr: 3.000e-05, eta: 0:07:46, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2324, loss_bbox: 0.3182, loss: 0.5505\n","2022-10-23 11:54:23,976 - mmdet - INFO - Epoch [20][230/440]\tlr: 3.000e-05, eta: 0:07:24, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2531, loss_bbox: 0.3172, loss: 0.5703\n","2022-10-23 11:54:45,070 - mmdet - INFO - Epoch [20][240/440]\tlr: 3.000e-05, eta: 0:07:03, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2451, loss_bbox: 0.3251, loss: 0.5702\n","2022-10-23 11:55:06,209 - mmdet - INFO - Epoch [20][250/440]\tlr: 3.000e-05, eta: 0:06:42, time: 2.114, data_time: 0.016, memory: 11233, loss_cls: 0.2284, loss_bbox: 0.3205, loss: 0.5489\n","2022-10-23 11:55:27,354 - mmdet - INFO - Epoch [20][260/440]\tlr: 3.000e-05, eta: 0:06:21, time: 2.115, data_time: 0.016, memory: 11233, loss_cls: 0.2395, loss_bbox: 0.3152, loss: 0.5547\n","2022-10-23 11:55:48,498 - mmdet - INFO - Epoch [20][270/440]\tlr: 3.000e-05, eta: 0:06:00, time: 2.114, data_time: 0.015, memory: 11233, loss_cls: 0.2580, loss_bbox: 0.3232, loss: 0.5812\n","2022-10-23 11:56:09,622 - mmdet - INFO - Epoch [20][280/440]\tlr: 3.000e-05, eta: 0:05:38, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2577, loss_bbox: 0.3165, loss: 0.5742\n","2022-10-23 11:56:30,739 - mmdet - INFO - Epoch [20][290/440]\tlr: 3.000e-05, eta: 0:05:17, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2423, loss_bbox: 0.3255, loss: 0.5678\n","2022-10-23 11:56:51,874 - mmdet - INFO - Epoch [20][300/440]\tlr: 3.000e-05, eta: 0:04:56, time: 2.113, data_time: 0.016, memory: 11233, loss_cls: 0.2472, loss_bbox: 0.3172, loss: 0.5644\n","2022-10-23 11:57:13,019 - mmdet - INFO - Epoch [20][310/440]\tlr: 3.000e-05, eta: 0:04:35, time: 2.114, data_time: 0.016, memory: 11233, loss_cls: 0.2383, loss_bbox: 0.3185, loss: 0.5568\n","2022-10-23 11:57:34,153 - mmdet - INFO - Epoch [20][320/440]\tlr: 3.000e-05, eta: 0:04:14, time: 2.113, data_time: 0.016, memory: 11233, loss_cls: 0.2597, loss_bbox: 0.3415, loss: 0.6012\n","2022-10-23 11:57:55,271 - mmdet - INFO - Epoch [20][330/440]\tlr: 3.000e-05, eta: 0:03:52, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2571, loss_bbox: 0.3190, loss: 0.5761\n","2022-10-23 11:58:16,404 - mmdet - INFO - Epoch [20][340/440]\tlr: 3.000e-05, eta: 0:03:31, time: 2.113, data_time: 0.016, memory: 11233, loss_cls: 0.2179, loss_bbox: 0.3030, loss: 0.5208\n","2022-10-23 11:58:37,524 - mmdet - INFO - Epoch [20][350/440]\tlr: 3.000e-05, eta: 0:03:10, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2480, loss_bbox: 0.3243, loss: 0.5724\n","2022-10-23 11:58:58,616 - mmdet - INFO - Epoch [20][360/440]\tlr: 3.000e-05, eta: 0:02:49, time: 2.109, data_time: 0.017, memory: 11233, loss_cls: 0.2606, loss_bbox: 0.3242, loss: 0.5848\n","2022-10-23 11:59:19,720 - mmdet - INFO - Epoch [20][370/440]\tlr: 3.000e-05, eta: 0:02:28, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2465, loss_bbox: 0.3157, loss: 0.5622\n","2022-10-23 11:59:40,836 - mmdet - INFO - Epoch [20][380/440]\tlr: 3.000e-05, eta: 0:02:07, time: 2.112, data_time: 0.016, memory: 11233, loss_cls: 0.2402, loss_bbox: 0.3166, loss: 0.5569\n","2022-10-23 12:00:01,929 - mmdet - INFO - Epoch [20][390/440]\tlr: 3.000e-05, eta: 0:01:45, time: 2.109, data_time: 0.016, memory: 11233, loss_cls: 0.2582, loss_bbox: 0.3354, loss: 0.5935\n","2022-10-23 12:00:23,033 - mmdet - INFO - Epoch [20][400/440]\tlr: 3.000e-05, eta: 0:01:24, time: 2.110, data_time: 0.016, memory: 11233, loss_cls: 0.2486, loss_bbox: 0.3230, loss: 0.5715\n","2022-10-23 12:00:44,145 - mmdet - INFO - Epoch [20][410/440]\tlr: 3.000e-05, eta: 0:01:03, time: 2.111, data_time: 0.016, memory: 11233, loss_cls: 0.2409, loss_bbox: 0.3181, loss: 0.5590\n","2022-10-23 12:01:05,282 - mmdet - INFO - Epoch [20][420/440]\tlr: 3.000e-05, eta: 0:00:42, time: 2.114, data_time: 0.017, memory: 11233, loss_cls: 0.2390, loss_bbox: 0.3322, loss: 0.5712\n","2022-10-23 12:01:26,420 - mmdet - INFO - Epoch [20][430/440]\tlr: 3.000e-05, eta: 0:00:21, time: 2.114, data_time: 0.017, memory: 11233, loss_cls: 0.2545, loss_bbox: 0.3183, loss: 0.5729\n","2022-10-23 12:01:47,565 - mmdet - INFO - Epoch [20][440/440]\tlr: 3.000e-05, eta: 0:00:00, time: 2.115, data_time: 0.016, memory: 11233, loss_cls: 0.2185, loss_bbox: 0.3048, loss: 0.5234\n","2022-10-23 12:01:47,643 - mmdet - INFO - Saving checkpoint at 20 epochs\n"]},{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 878/878, 8.7 task/s, elapsed: 101s, ETA:     0s"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 12:03:33,841 - mmdet - INFO - Evaluating bbox...\n"]},{"output_type":"stream","name":"stdout","text":["Loading and preparing results...\n","DONE (t=0.29s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.44s).\n","Accumulating evaluation results...\n"]},{"output_type":"stream","name":"stderr","text":["2022-10-23 12:03:42,290 - mmdet - INFO - \n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.284\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.083\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.043\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.106\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.149\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.294\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.294\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.153\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.342\n","\n","2022-10-23 12:03:42,407 - mmdet - INFO - Epoch(val) [20][878]\tbbox_mAP: 0.1140, bbox_mAP_50: 0.2840, bbox_mAP_75: 0.0830, bbox_mAP_s: 0.0430, bbox_mAP_m: 0.1060, bbox_mAP_l: 0.1490, bbox_mAP_copypaste: 0.114 0.284 0.083 0.043 0.106 0.149\n"]},{"output_type":"stream","name":"stdout","text":["DONE (t=2.21s).\n"]}]},{"cell_type":"code","source":["PATH=f'/content/drive/MyDrive/project/vinBigData/retina/model/epoch_{EPOCHS}_retina.pt'\n","torch.save(model, PATH)"],"metadata":{"id":"H6ttrMf5ctLq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MfQ-yspZLuuI"},"source":["## Test the trained detector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xo08PUlOav6_"},"outputs":[],"source":["from mmdet.apis import inference_detector, show_result_pyplot\n","\n","import os\n","from glob import glob\n","from tqdm.notebook import tqdm\n","test_img = os.path.join(base_path, \"test\")\n","\n","test_file = glob(test_img+\"/*.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2fzHqjaa2WZ"},"outputs":[],"source":["len(test_file), test_file[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tg1onolI6LIu"},"outputs":[],"source":["model = torch.load('/content/drive/MyDrive/project/vinBigData/retina/1/epoch_20.pth')"]},{"cell_type":"markdown","metadata":{"id":"PSgZnyGkGhoZ"},"source":["테스트 데이터 하나를 추론해봅니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ooe3M0fcnHB"},"outputs":[],"source":["img = mmcv.imread(test_file[844])\n","\n","model.cfg = cfg\n","predictions = inference_detector(model, img)\n","show_result_pyplot(model, img, predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hGT9w7TcxIQ"},"outputs":[],"source":["len(predictions), predictions[0].shape, predictions[1].shape, predictions[2].shape, predictions[3].shape,predictions[4].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGVKD7Xr6LIw"},"outputs":[],"source":["def format_prediction_string(labels, boxes, scores):\n","    pred_strings = []\n","    for j in zip(labels, scores, boxes):\n","        pred_strings.append(\"{0} {1:.4f} {2} {3} {4} {5}\".format(\n","            j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n","        # labels scores box_xmin  box_xmax box_ymin box_ymax     \n","    return \" \".join(pred_strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a356W2zciQ87"},"outputs":[],"source":["# Ref : https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer?scriptVersionId=68887943&cellId=21\n","\n","\n","score_threshold = 0.5 # 0.8, 0.3, cfg.model.test_cfg.rcnn.score_thr\n","results = []\n","\n","\n","for index, img_path in tqdm(enumerate(test_file), total = len(test_file)):\n","    image_id = img_path.split(\"/\")[-1].split(\".\")[0]\n","    file_name = img_path.split(\"/\")[-1].split(\".\")[0]+\".png\"\n","    result = {\n","        'image_id': image_id,\n","        'PredictionString': '14 1.0 0 0 1 1'\n","    }\n","\n","    img = mmcv.imread(img_path)\n","    predictions = inference_detector(model, img)\n","    boxes, scores, labels = (list(), list(), list())\n","\n","    for k, cls_result in enumerate(predictions):\n","        # print(\"cls_result\", cls_result)\n","        if cls_result.size != 0:\n","            if len(labels)==0:\n","                boxes = np.array(cls_result[:, :4])\n","                scores = np.array(cls_result[:, 4])\n","                labels = np.array([k+1]*len(cls_result[:, 4]))\n","            else:    \n","                boxes = np.concatenate((boxes, np.array(cls_result[:, :4])))\n","                scores = np.concatenate((scores, np.array(cls_result[:, 4])))\n","                labels = np.concatenate((labels, [k+1]*len(cls_result[:, 4])))\n","\n","    if len(labels) != 0:\n","        # 라벨 -1 씩 SHIFT\n","        labels = labels - 1\n","        # no finding 이 -1에서 14로 이동!\n","        labels[labels == -1] = 14\n","\n","        indexes = np.where(scores > score_threshold)\n","        # print(indexes)\n","        boxes = boxes[indexes]\n","        scores = scores[indexes]\n","        labels = labels[indexes]\n","        \n","        # 0.5 보다 confidence 높은 박스가 있다는 의미\n","        if len(boxes) > 0:\n","          result = {\n","              'image_id': image_id,\n","              'PredictionString': format_prediction_string(labels, boxes, scores)\n","          }\n","    # result list를 계속 append!\n","    results.append(result)\n"]},{"cell_type":"markdown","metadata":{"id":"rvbYFhSHaA8K"},"source":["##Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rM0DgQfcndjA"},"outputs":[],"source":["import pandas as pd\n","submission = pd.DataFrame(results)\n","submission.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zcpm4fEngog"},"outputs":[],"source":["submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrSsZXgc6LIx"},"outputs":[],"source":["submission.to_csv(f'/content/drive/MyDrive/project/vinBigData/submission/swin/mmdedtection_colab_swin_{EPOCHS}_1.csv', index=False)"]},{"cell_type":"code","source":[],"metadata":{"id":"_N0IrB9hEoND"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.8.13 ('pytorch112_p38')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"58d57aa79b850236b521150a1202e790a96ac8259ac3baa83cc74f3e58246589"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"4764abef8afb4802b01964fa55d50820":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e04563ede554138a83a8dae5c48e337","IPY_MODEL_6a160e47e02442e8b0545888dcf5b439","IPY_MODEL_bf10b0d445254ffdb3f5a9c3f20bac54"],"layout":"IPY_MODEL_e53aa202d15b413cb27e33b2b89822e0"}},"9e04563ede554138a83a8dae5c48e337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42635de59f024efa86ddbea2b0dd2968","placeholder":"​","style":"IPY_MODEL_c14556e47fd84935b4fc25cbc3ff07b6","value":"100%"}},"6a160e47e02442e8b0545888dcf5b439":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c461c3ec235c47b8a4a45b5ee63f3752","max":3516,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5569d8086854eddb00fb328f9300153","value":3516}},"bf10b0d445254ffdb3f5a9c3f20bac54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_449f861e4c2f49d5a846f67a4337881f","placeholder":"​","style":"IPY_MODEL_85adceb7623f40d0bbc875c5aa5d1042","value":" 3516/3516 [00:08&lt;00:00, 412.95it/s]"}},"e53aa202d15b413cb27e33b2b89822e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42635de59f024efa86ddbea2b0dd2968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c14556e47fd84935b4fc25cbc3ff07b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c461c3ec235c47b8a4a45b5ee63f3752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5569d8086854eddb00fb328f9300153":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"449f861e4c2f49d5a846f67a4337881f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85adceb7623f40d0bbc875c5aa5d1042":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d7e77eec8a94414bef0c8b925393669":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aebd82a928844f99b89a5c92176fb348","IPY_MODEL_f4299b73183942dca9f600a24f0f1132","IPY_MODEL_ff2f845f09ae48c281a81401ddf64f0c"],"layout":"IPY_MODEL_36a8003e0f8b4b93bc9499a004a923de"}},"aebd82a928844f99b89a5c92176fb348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2287050321f045558fb065a63b9b28cb","placeholder":"​","style":"IPY_MODEL_aee173ae879045a297b2b45d1bf3133a","value":"100%"}},"f4299b73183942dca9f600a24f0f1132":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d73715fd6f43398572612eec4211b5","max":878,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19fab9a11c68408ca43e5e86404d6d8f","value":878}},"ff2f845f09ae48c281a81401ddf64f0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba0bc81eeac048879a33a1139a4cc472","placeholder":"​","style":"IPY_MODEL_c259200282614c17810d9b531bf04c49","value":" 878/878 [00:00&lt;00:00, 1050.60it/s]"}},"36a8003e0f8b4b93bc9499a004a923de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2287050321f045558fb065a63b9b28cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee173ae879045a297b2b45d1bf3133a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7d73715fd6f43398572612eec4211b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19fab9a11c68408ca43e5e86404d6d8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba0bc81eeac048879a33a1139a4cc472":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c259200282614c17810d9b531bf04c49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}